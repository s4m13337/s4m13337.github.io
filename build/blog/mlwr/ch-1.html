<!DOCTYPE html>
<html>
  <head>
    <title>Chapter 1: The Machine Learning Landscape - s4m13337</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="/static/style.css">
  </head>
  <body>
  	<div class="container">
  		<h1 class="header">s4m13337's website</h1>

      <!-- Navigation -->
      
      
      <nav>
        <ul>
        
          <li><a href="/index.html">üè† Home</a></li>
        
          <li><a href="/about.html">‚ÑπÔ∏è About</a></li>
        
          <li><a href="/blog/index.html">üìù Blog</a></li>
        
          <li><a href="/contact.html">‚úâÔ∏è Contact</a></li>
        
        </ul>
      </nav>

      <!-- Content area -->
      <hr>
      <div class="content">
	<h1>Chapter 1: The Machine Learning Landscape</h1>
	<p><h3>What does <em>data mining</em> mean?</h3>
<p>Applying machine learning techniques to large amout of data to detect patterns that are not immediately apparent is called <em>data mining</em>.</p>
<h3>What types of Machine Learning systems can you classify?</h3>
<ul>
<li>Based on human supervision<ul>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
<li>Semisupervised learning</li>
<li>Reinforcement learning</li>
</ul>
</li>
<li>Whether they can learn on the fly<ul>
<li>Online learning</li>
<li>Batch learning</li>
</ul>
</li>
<li>Whether the learn from new instances or by comparing entire models<ul>
<li>Instance based</li>
<li>Model based</li>
</ul>
</li>
</ul>
<h3>Describe the four major categories shortly and point out the most important algorithms (supervised learning, unsupervised learning, semisupervised learning, reinforcement learning)</h3>
<ul>
<li><strong>Supervised learning</strong><ul>
<li>In supervised learning, the example data fed to the algorithm includes the desired solutions, called labels/target numeric vlaues.</li>
<li>There are two types of supervised learning task: Classification and Regression. In classification, our goal is to predict the target label and in Regression, the goal is to predict a target numeric value.</li>
<li>The most commonly used algorithms for supervised learning are Linear Regression, Logistic Regression, Support Vector Machines, Decision Trees, Random Forests and Neural Networks.</li>
</ul>
</li>
<li><strong>Unsupervised learning</strong><ul>
<li>In this case the example data does not contain any labels.</li>
<li>Some important unsupervised learning alogirthms are as follows:<ol>
<li>Clustering<ul>
<li>K-Means</li>
<li>DBSCAN</li>
<li>Hierarchical Cluster Analysis (HCA)</li>
</ul>
</li>
<li>Anomaly/Novelty detection<ul>
<li>One class SVM</li>
<li>Isolation forest</li>
</ul>
</li>
<li>Visualizaion and dimensionality reduction<ul>
<li>Principal component analysis (PCA)</li>
<li>Kernel PCA</li>
<li>Local Linear Embedding (LLE)</li>
<li>t-Distributed Stochastic Neighbor Embedding (t-SNE)</li>
</ul>
</li>
<li>Association rule learning<ul>
<li>Apriori</li>
<li>Eclat</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
<li><strong>Semisupervised learning</strong><ul>
<li>Some algorithms can handle partially learned data very well. This is called semisupervised learning.</li>
<li>A good example is google photos. When you upload some photos, it automatically recognises that the same person shows up in several photos. (This is the unsupervised part, clustering in this case, done by Google)</li>
<li>Finally the system asks the human to label the person once. Just add one label per person and the system is able to name everyone in every photo.</li>
</ul>
</li>
<li><strong>Reinforcemnet learning</strong><ul>
<li>The learning system is called an agent. It observes the environment, selects and perfroms actions. Based on the action it receives either a reward or a penalty.</li>
<li>It learns by itself the best strategy, called the policy, to get the most reward over time.</li>
</ul>
</li>
</ul>
<h3>What is Batch and Online Learning?</h3>
<ul>
<li><strong>Batch learning</strong><ul>
<li>In batch learning, the system is incapable of learning incrementally.</li>
<li>It must be trained with all the data available.</li>
<li>This typically takes more time and computational resources and hence it is done offline. (a.k.a <em>offline learning</em>)</li>
</ul>
</li>
<li><strong>Online learning</strong><ul>
<li>In online learning, the system learns incrementally by feeding its data instances sequentially or in small groups called <em>mini batches</em>.</li>
<li>This method is best suited in applications involving continuous data flow like predicitng stock prices.</li>
<li>Online learning algorithms can be used to train systems with huge datasets that cannot fit in one machine's memory. This is called <em>out of the core learning</em>.</li>
</ul>
</li>
</ul>
<h3>What is Instance-Based and Model-Based Learning?</h3>
<ul>
<li><strong>Instance based learnign</strong><ul>
<li>In instance based learning, the system learns everything by heart.</li>
<li>When it is presented with a new instance, it generalizes the new instances by measuring the similarity with the learned examples.</li>
<li>Example: In a spam classifier, one similarity measurement is the number of common words. If an email has more number of common words found in a spam email, it gets classified as a spam.</li>
</ul>
</li>
<li><strong>Model based learning</strong><ul>
<li>In model based learning, the system creates a model out of the examples.</li>
<li>These models are then used to make predictions on new instances.</li>
</ul>
</li>
</ul>
<h3>What are common problems with Machine Learning algorithms and datasets?</h3>
<ul>
<li><strong>Bad data</strong><ul>
<li><strong>Insufficient quantity of training data</strong>: Machine learning requires huge amount of training data to work properly. For simple problems, it easily requires at least thousands of example data. In case of complex tasks like image/sound recognition, it requires millions of example data.</li>
<li><strong>Nonrepresentative training data</strong>: It is important to use training set that is representative of the cases that we wish to generalize. If the sample is too small, it introduces sampling noise (nonrepresentative data as a result of chance). But even large samples can be nonrepresentative if the sampling method is flawed (sampling bias).</li>
<li><strong>Poor quality data</strong>: If the training data is full or errors, outliers and noise (due to poor quality measurements), it makes it harder for the system to learn and detect patterns and thus it performs poor.       </li>
<li><strong>Irrelevant features</strong>: If the data contains too many irrelevant features or too few relevant features, the machine learning system will perform poor.</li>
</ul>
</li>
<li><strong>Bad algorithm</strong><ul>
<li><strong>Overfitting the training data</strong>: Overfitting occurs when the machine learning system performs well on the training data but fails to generalize on new data.    </li>
<li><strong>Underfitting the training data</strong>: Underfitting occurs when the selected system is too simple to capture the underlying complex structure of data.</li>
</ul>
</li>
</ul>
<h3>How can we do Testing and Validating?</h3>
<ul>
<li>The original dataset is split into two sets: training set and test set. After training a model, the error produced form taining set is called <em>training error</em> and the error from test set is called <em>generalization error</em>.</li>
<li>When evaluating many different models, it is better to create a validation set out of the training set. Multiple models are then trained on the reduced training set and evaluated on the validation set. The model that performs well on the validation is then chosen and trained on the whole dataset and evaluated on the test set to obtain the final generalization error.</li>
</ul>
<h3>What does the No Free Lunch theorem state?</h3>
<ul>
<li><em>If you make absolutely no assumptions about the data, there is no reason to prefer one model over any other.</em> - David Wolpert, 1996</li>
<li>There is no model that is apriori guaranted to work better. The only way to know which one works best is to evaluate them all. Since this is not possible, in practice, we make reasonable assumptions about the data and evaluate only a few reasonable models.</li>
</ul></p>
</div>
      <hr>

     <!-- Footer -->
     

<footer>
  <center>&copy; s4m13337 All Rights Reserved</center>
</footer>

</div>
</body>
</html>